{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the concept and document data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.concept import Concept\n",
    "from src.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/processed\")\n",
    "\n",
    "document_dir = data_dir / \"documents\"\n",
    "document_files = list(document_dir.glob(\"*.json\"))\n",
    "documents = [Document.load(file) for file in tqdm(document_files)]\n",
    "\n",
    "concept_dir = data_dir / \"concepts\"\n",
    "concept_files = list(concept_dir.glob(\"*.json\"))\n",
    "concepts = [Concept.load(file) for file in tqdm(concept_files)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a mapping from concept id to preferred label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_id_to_label = {concept.id: concept.preferred_label for concept in concepts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count instances of each concept being found in the document data - which are most and least common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_found_concepts = Counter(\n",
    "    [\n",
    "        concept_id_to_label[concept_id]\n",
    "        for document in documents\n",
    "        for concept_id in document.concepts\n",
    "    ]\n",
    ")\n",
    "all_found_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a dataframe with the document-wise counts of each concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_concept_counts = {\n",
    "    document.id: dict(\n",
    "        Counter([concept_id_to_label[concept_id] for concept_id in document.concepts])\n",
    "    )\n",
    "    for document in documents\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(document_concept_counts).T.fillna(0).astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the cooccurrence matrix of the concepts in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_interactions = df.T.dot(df)\n",
    "concept_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalise the concept interactions and then plot a heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_concept_interactions = concept_interactions / np.sqrt(\n",
    "    concept_interactions.values.diagonal()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "sns.heatmap(normalised_concept_interactions, cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the sentences which contain concepts, embed them, and plot the 2d UMAP of the embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = set()\n",
    "for document in tqdm(documents):\n",
    "    for concept_span in document.concept_spans:\n",
    "        for sentence_span in document.sentence_spans:\n",
    "            if (\n",
    "                concept_span.start_index >= sentence_span.start_index\n",
    "                and concept_span.end_index <= sentence_span.end_index\n",
    "            ):\n",
    "                sentences.add(\n",
    "                    document.text[sentence_span.start_index : sentence_span.end_index]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(sentences)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "sentence_embeddings = []\n",
    "for sentence in tqdm(sentences[:5000]):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        sentence_embeddings.append(outputs.pooler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.stack(sentence_embeddings).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = UMAP(n_components=2)\n",
    "embeddings_2d = umap.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": embeddings_2d[:, 0],\n",
    "        \"y\": embeddings_2d[:, 1],\n",
    "        \"sentence\": sentences[:5000],\n",
    "    }\n",
    ")\n",
    "fig = px.scatter(\n",
    "    df, x=\"x\", y=\"y\", hover_data={\"x\": False, \"y\": False, \"sentence\": True}\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
