"""
Use the Claude API to generate domain-specific relevance judgements for tribunal docs.

Based loosely on "Large language models can accurately predict searcher preferences"
https://arxiv.org/abs/2309.10621

We use NDCG@k as our gold-standard metric for evaluating the performance of the search
engine. NDCG is based on comparing the ranking of the search engine with the ideal
ranking of the search engine according to a set of relevance scores. These are usually
manually generated by human judges, but recent work has shown that large language models
can be used to generate relevance scores that are well-correlated with human judgements.

We use a naive, unoptimised query to retrieve the top 1000 documents from the
corpus for a set of known search terms. We then use the Claude API to generate relevance
scores for these documents. We can then use these relevance scores to evaluate the
performance of the search engine when developing new ranking algorithms.
"""

import json
from pathlib import Path

from elasticsearch import Elasticsearch
from rich.console import Console
from rich.progress import track

console = Console()

with open("data/raw/known_search_terms.json") as f:
    search_terms = json.load(f)

with console.status("Setting up directories..."):
    data_dir = Path("data")
    relevance_eval_dir = data_dir / "eval" / "relevance"
    candidate_docs_dir = relevance_eval_dir / "candidate_docs"
    judgements_dir = relevance_eval_dir / "judgements"
    candidate_docs_dir.mkdir(parents=True, exist_ok=True)
    judgements_dir.mkdir(parents=True, exist_ok=True)
console.print("üìÅ Set up data directories", style="green")


with console.status("Setting up Elasticsearch index..."):
    es = Elasticsearch(
        hosts=[{"host": "localhost", "port": 9200, "scheme": "http"}],
        request_timeout=30,
        max_retries=10,
        retry_on_timeout=True,
    )
    index_name = "naive"
    if es.indices.exists(index=index_name):
        es.indices.delete(index=index_name)
    es.indices.create(
        index=index_name,
        settings={
            "analysis": {
                "analyzer": {
                    "naive": {
                        "type": "custom",
                        "tokenizer": "standard",
                        "char_filter": ["html_strip"],
                        "filter": ["lowercase", "asciifolding"],
                    }
                }
            }
        },
        mappings={"properties": {"text": {"type": "text", "analyzer": "naive"}}},
    )
console.print(f"üöß Set up Elasticsearch index: {index_name}", style="green")

documents_dir = data_dir / "processed" / "documents"
for doc in track(
    list(documents_dir.glob("*.json")),
    description="Indexing documents...",
    console=console,
    transient=True,
):
    with doc.open() as f:
        data = json.load(f)
    text = data["title"] + " " + data["text"]
    es.index(index="naive", document={"text": text}, id=doc.stem)
console.print("ü§ì Indexed documents", style="green")

for term in track(
    search_terms, "Retrieving candidate documents...", console=console, transient=True
):
    res = es.search(index="naive", query={"match": {"text": term}}, size=1000)
    candidates = [hit["_id"] for hit in res["hits"]["hits"]]
    file_stem = term.replace(" ", "_")
    with open(candidate_docs_dir / f"{file_stem}.json", "w") as f:
        json.dump(candidates, f)
console.print("üîç Retrieved candidate documents for eval search terms", style="green")
console.print(f"üíæ Saved candidate document IDs to {candidate_docs_dir}", style="green")

es.indices.delete(index=index_name)
console.print(f"üßπ Deleted Elasticsearch index: {index_name}", style="green")
